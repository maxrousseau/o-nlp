{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88916b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cef7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_dataset = Dataset.load_from_disk(\"../oqa_v1.0_shuffled_split/bin/val\")\n",
    "val_dataset = Dataset.load_from_disk(\"tmp/bin/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d343b797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'answer_sentence', 'topic', 'reference', 'id'],\n",
       "    num_rows: 55\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a771a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a471218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llm_inference import GpuInference\n",
    "tt5 = GpuInference(model_checkpoint = \"google/t5-efficient-tiny\",\n",
    "             tokenizer_checkpoint = \"google/t5-efficient-tiny\",\n",
    "             int8=False,\n",
    "             dataset=val_dataset,\n",
    "            prompt_fmt=\"uniqa\")\n",
    "prompts = tt5.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c4ca1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'within about the first 100 days',\n",
       " 'prompt': 'regarding mandibular expansion with the lip bumper, when does the greatest amount of expansion occur?\\na critical aspect of nonextraction therapy is the creation of space. the results from this study show that lip bumper therapy is an effective means of accomplishing this task. other studies have demonstrated similar results using lip bumpers but have not focused on the attenuation in expansion that occurs during treatment. a major concern for orthodontists is treatment effectiveness and efficiency. it would be beneficial to know the specific amount of time required to achieve sufficient expansion using lip bumper therapy. this information would benefit the clinician by eliminating unnecessary lip bumper wear. this would obviously be desirable for the patients as well. the expansion achieved during lip bumper therapy is evenly distributed during treatment. however, the results clearly demonstrate that the expansion occurred unevenly and actually decreased with time. table 4 shows that for each of the measurements, the greatest amount of expansion, about 50% of the total, occurred within about the first 100 days. during the second and third time periods, about 40% of the total amount of expansion will have occurred. during the last two time segments, the percentage of total expansion achieved is only about 10%. therefore, about 90% of the expansion was completed in these cases within the first 300 days, and treatment effectiveness after this point yielded only about 10% of the total expansion. knowledge of how the lip bumper alters the equilibrium between the lingual and the vestibular forces surrounding the teeth may explain the results of this study. we speculate that upon insertion of the appliance, a new system of forces is set up around the teeth. with time, the dentition will adapt to the new force system and reestablish equilibrium. the gross movements in this process occur early in treatment, and as the teeth approach their new equilibrium position, their movement tapers down. although we observed most of the expansion occurring at the start of treatment, we did observe some patients who had a higher than normal percentage of tooth movement toward the end of treatment. we speculate that this could be related to whether the appliance was adjusted toward the end of lip bumper therapy. more specifically, most cases in our study had minimal adjustments to the lip bumper toward the end of treatment. however, for those cases that required such adjustments, the force system was still undergoing changes, thus not approaching equilibrium.',\n",
       " 'id': '289a5803-09b0-4074-a3b2-f7f7b823ef3a'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c1ac027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495f66294a6343639181ab25e518af8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/628 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0181be7ad38a4d568a1ee8a254708ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389c8fd998d34d458a6ce19f153881c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function GpuInference.genseq.<locals>.<lambda> at 0x00000171C914EC10> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = tt5.genseq(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18e466ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[1918,  388,   26,  ...,    0,    0,    0],\n",
       "        [1918,    8,    3,  ...,    0,    0,    0],\n",
       "        [1918,  197,  102,  ...,    0,    0,    0],\n",
       "        [1918,  388,   26,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06609dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
