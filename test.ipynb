{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import load_data\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] :: 2023-01-13 14:09:12,367 @ datasets.builder :: Found cached dataset squad (C:/Users/roum5/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 38.20it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = load_data.loadSquadMI(n=4)\n",
    "tiny_squad = Dataset.from_dict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_default_config = {\n",
    "    \"name\": \"bart-default\",\n",
    "    \"lr\": 2e-5,\n",
    "    \"num_epochs\": 1,\n",
    "    \"lr_scheduler\": True,\n",
    "    \"checkpoint\": \"facebook/bart-base\",\n",
    "    \"checkpoint_savedir\": \"./ckpt\",\n",
    "    \"train_dev_dataset\": None,\n",
    "    \"val_dev_dataset\": None,\n",
    "    \"train_dataset\": tiny_squad,\n",
    "    \"test_dataset\": tiny_squad,\n",
    "    \"max_seq_length\": 384,\n",
    "    \"max_ans_length\": 128,\n",
    "    \"stride\": 128,\n",
    "    \"padding\": \"max_length\",\n",
    "    \"seed\": 0,\n",
    "    \"prefix\": True,\n",
    "    \"train_prefix\": True,\n",
    "    \"unfreeze\": False, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] :: 2023-01-13 14:49:32,735 @ bart :: tokenizer initialized\n",
      "[INFO] :: 2023-01-13 14:49:35,525 @ bart :: prefix bart for mask infilling model initialized\n",
      "[INFO] :: 2023-01-13 14:49:35,526 @ bart :: training prefix parameters\n",
      "[INFO] :: 2023-01-13 14:49:35,551 @ bart :: training dataset processed and dataloaders created\n",
      "[INFO] :: 2023-01-13 14:49:35,645 @ bart :: validation dataset processed and dataloaders created\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED  ANS Saint Bernadette Soubirous\n",
      "PRED  ANS a copper statue of Christ\n",
      "PRED  ANS the Main Building\n",
      "PRED  ANS a Marian place of prayer and reflection\n",
      "PRED  ANS a golden statue of the Virgin Mary\n",
      "PRED  ANS September 1876\n",
      "PRED  ANS twice\n",
      "PRED  ANS The Observer\n",
      "PRED  ANS three\n",
      "PRED  ANS 1987\n",
      "Epoch: 0, Loss: 0.7587692141532898, Validation F1: {'exact_match': 0.0, 'f1': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] :: 2023-01-13 14:50:12,873 @ bart :: new best model saved!\n",
      "[INFO] :: 2023-01-13 14:50:15,533 @ bart :: best model reloaded!\n",
      "100%|██████████| 3/3 [00:40<00:00, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model f1 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsbart import FsBART\n",
    "fsb_model = FsBART(**bart_default_config)\n",
    "fsb_model.finetune(\"run\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] :: 2023-01-13 15:11:47,632 @ datasets.builder :: Found cached dataset squad (C:/Users/roum5/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] :: 2023-01-13 16:13:34,516 @ datasets.builder :: Found cached dataset squad (C:/Users/roum5/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 3/3 [1:35:05<00:00, 1901.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m squad_train \u001b[39m=\u001b[39m load_data\u001b[39m.\u001b[39;49mloadSquadMI(\u001b[39mset\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m squad_train \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(squad_train)\n\u001b[0;32m      4\u001b[0m \u001b[39m# squad_test = load_data.loadSquadMI(set=\"validation\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# squad_test = Dataset.from_dict(squad_test)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roum5\\source\\o-nlp\\load_data.py:185\u001b[0m, in \u001b[0;36mloadSquadMI\u001b[1;34m(n, set)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m squad_subset\n\u001b[0;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     squad_subset \u001b[39m=\u001b[39m formatToMI(raw_datasets[\u001b[39mset\u001b[39;49m])\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m squad_subset\n",
      "File \u001b[1;32mc:\\Users\\roum5\\source\\o-nlp\\load_data.py:125\u001b[0m, in \u001b[0;36mformatToMI\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[0;32m    124\u001b[0m     question \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[1;32m--> 125\u001b[0m     answer \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39manswers\u001b[39;49m\u001b[39m\"\u001b[39;49m][i][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    126\u001b[0m     context \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[0;32m    128\u001b[0m     masked_strings\u001b[39m.\u001b[39mappend(\n\u001b[0;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mQuestion: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Answer: <mask>. Context: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(question, context)\n\u001b[0;32m    130\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:2228\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2227\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[0;32m   2229\u001b[0m         key,\n\u001b[0;32m   2230\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\arrow_dataset.py:2213\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2211\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, decoded\u001b[39m=\u001b[39mdecoded, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2212\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 2213\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[0;32m   2214\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[0;32m   2215\u001b[0m )\n\u001b[0;32m   2216\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    531\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[0;32m    533\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    534\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:283\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_row(pa_table)\n\u001b[0;32m    282\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_column(pa_table)\n\u001b[0;32m    284\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:316\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_column\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     column \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpython_arrow_extractor()\u001b[39m.\u001b[39;49mextract_column(pa_table)\n\u001b[0;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoded:\n\u001b[0;32m    318\u001b[0m         column \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_features_decoder\u001b[39m.\u001b[39mdecode_column(column, pa_table\u001b[39m.\u001b[39mcolumn_names[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\datasets\\formatting\\formatting.py:143\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_column\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_column\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m pa_table\u001b[39m.\u001b[39;49mcolumn(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto_pylist()\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\pyarrow\\table.pxi:1258\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray.to_pylist\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\pyarrow\\array.pxi:1468\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.to_pylist\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\site-packages\\pyarrow\\scalar.pxi:705\u001b[0m, in \u001b[0;36mpyarrow.lib.StructScalar.as_py\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\roum5\\Envs\\o-nlp\\lib\\_collections_abc.py:672\u001b[0m, in \u001b[0;36mMapping.keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkeys\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mD.keys() -> a set-like object providing a view on D\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms keys\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m     \u001b[39mreturn\u001b[39;00m KeysView(\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "squad_train = load_data.loadSquadMI(set=\"train\")\n",
    "squad_train = Dataset.from_dict(squad_train)\n",
    "\n",
    "# squad_test = load_data.loadSquadMI(set=\"validation\")\n",
    "# squad_test = Dataset.from_dict(squad_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e347cf33e39658ad5379615e90ad4f79b8760426ae44e8daf2e52468f171ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
